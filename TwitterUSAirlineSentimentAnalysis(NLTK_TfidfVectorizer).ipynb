{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Twitter US Airline Sentiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tweets in training data:10980\nTweets in testing data:3660\nTotal Tweets -->  14640\n"
    }
   ],
   "source": [
    "train = pd.read_csv('twitter_x_y_train.csv')\n",
    "test = pd.read_csv('twitter_x_test.csv')\n",
    "print(\"Tweets in training data:{}\".format(train.shape[0]))\n",
    "print(\"Tweets in testing data:{}\".format(test.shape[0]))\n",
    "print(\"Total Tweets --> \",train.shape[0]+test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "negative    6851\nneutral     2327\npositive    1802\nName: airline_sentiment, dtype: int64\n"
    }
   ],
   "source": [
    "print(train.airline_sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['tweet_id', 'airline_sentiment', 'airline', 'airline_sentiment_gold',\n       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n       'tweet_created', 'tweet_location', 'user_timezone'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['tweet_id', 'airline', 'airline_sentiment_gold',\n",
    "       'name', 'negativereason_gold', 'retweet_count','tweet_coord',\n",
    "       'tweet_created', 'tweet_location', 'user_timezone']\n",
    "train.drop(drop_cols, axis = 1, inplace=True)\n",
    "test.drop(drop_cols, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      airline_sentiment                                               text\n0              negative  @SouthwestAir I am scheduled for the morning, ...\n1              positive  @SouthwestAir seeing your workers time in and ...\n2              positive  @united Flew ORD to Miami and back and  had gr...\n3              negative     @SouthwestAir @dultch97 that's horse radish üò§üê¥\n4              negative  @united so our flight into ORD was delayed bec...\n...                 ...                                                ...\n10975           neutral                            @AmericanAir followback\n10976          positive  @united thanks for the help. Wish the phone re...\n10977          negative  @usairways the. Worst. Ever. #dca #customerser...\n10978          negative  @nrhodes85: look! Another apology. DO NOT FLY ...\n10979          negative  @united you are by far the worst airline. 4 pl...\n\n[10980 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>airline_sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>negative</td>\n      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive</td>\n      <td>@SouthwestAir seeing your workers time in and ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>positive</td>\n      <td>@united Flew ORD to Miami and back and  had gr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>negative</td>\n      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negative</td>\n      <td>@united so our flight into ORD was delayed bec...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10975</th>\n      <td>neutral</td>\n      <td>@AmericanAir followback</td>\n    </tr>\n    <tr>\n      <th>10976</th>\n      <td>positive</td>\n      <td>@united thanks for the help. Wish the phone re...</td>\n    </tr>\n    <tr>\n      <th>10977</th>\n      <td>negative</td>\n      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n    </tr>\n    <tr>\n      <th>10978</th>\n      <td>negative</td>\n      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n    </tr>\n    <tr>\n      <th>10979</th>\n      <td>negative</td>\n      <td>@united you are by far the worst airline. 4 pl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10980 rows √ó 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = (train[\"text\"])\n",
    "target_data = set(train['airline_sentiment'])\n",
    "test_data = (test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = []\n",
    "tweets_test = []\n",
    "for sentiment in target_data:\n",
    "    \n",
    "    #---->Training data (text,sentiment)\n",
    "    sentiment_rows_train = (train['airline_sentiment'] == sentiment)\n",
    "    current_train=train[sentiment_rows_train]\n",
    "    current_train.reset_index(drop=True,inplace=True)\n",
    "    for tweet in (list(current_train['text'])):\n",
    "        tweets_train.append(((word_tokenize(tweet)), sentiment))    \n",
    "    \n",
    "#---->Testing data (text)\n",
    "for j in test_data:\n",
    "    tweets_test.append((word_tokenize(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10980\n3660\n"
    }
   ],
   "source": [
    "print(len(tweets_train))\n",
    "print(len(tweets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_train[:5]\n",
    "#tweets_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(tweets_train)\n",
    "#tweets_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetLemmatizer and Pos Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "\n",
    "stops.update(punctuations)\n",
    "#stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_words(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10980"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tweets_train = [(get_clean_words(tweet),sentiment) for tweet,sentiment in tweets_train]\n",
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3660"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tweets_test = [get_clean_words(tweet) for tweet in tweets_test]\n",
    "len(tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data in X(2d array) and Y(Target) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tweet = [\" \".join(tweet) for tweet, category in tweets_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [sentiment for document, sentiment in tweets_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tweet_test = [\" \".join(tweet) for tweet in tweets_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default 75:25\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_tweet, sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "matrix([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "Tfid_Vectorizer=TfidfVectorizer(ngram_range=(1,2),max_features=2000)\n",
    "x_train_features = Tfid_Vectorizer.fit_transform(x_train)\n",
    "x_train_features.todense()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features = Tfid_Vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<2745x2000 sparse matrix of type '<class 'numpy.float64'>'\n\twith 26175 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x_test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn SVC Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf',C=100,gamma=0.0001)\n",
    "svc.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training accuracy: 0.6329083181542198\n"
    }
   ],
   "source": [
    "print(\"Training accuracy:\",svc.score(x_train_features, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training accuracy: 0.6225865209471767\n"
    }
   ],
   "source": [
    "print(\"Training accuracy:\",svc.score(x_test_features, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10,min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, n_estimators=10,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "clf.fit(x_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training accuracy: 0.9634486945962356\n"
    }
   ],
   "source": [
    "print(\"Training accuracy:\",clf.score(x_train_features, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Testing accuracy: 0.7449908925318761\n"
    }
   ],
   "source": [
    "print(\"Testing accuracy:\",clf.score(x_test_features, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict twitter_x_test (text_tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = Tfid_Vectorizer.transform(text_tweet_test)\n",
    "test_pred = clf.predict(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_pred)\n",
    "#df.to_csv('twitter_randomforest_pred.csv',header=False,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}